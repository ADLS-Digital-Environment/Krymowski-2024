<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.7.2">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>2&nbsp; Theoretical Framework – Monitoring of coastal changes using satellite imagery: A case study of Unawatuna</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
  margin-bottom: 0em;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<link href="./methodology.html" rel="next">
<link href="./intro.html" rel="prev">
<script src="site_libs/quarto-html/quarto.js"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting-07c16812f08c4a1591d6ec4fc46327fa.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap-7930a387d1d9c5a851eba23757f768d8.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>


</head>

<body class="nav-sidebar floating">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" role="button" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./theoretical-framework.html"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Theoretical Framework</span></a></li></ol></nav>
        <a class="flex-grow-1" role="navigation" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
      <button type="button" class="btn quarto-search-button" aria-label="Search" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="./">Monitoring of coastal changes using satellite imagery: A case study of Unawatuna</a> 
        <div class="sidebar-tools-main">
    <a href="./Krymowski2024.pdf" title="Download PDF" class="quarto-navigation-tool px-1" aria-label="Download PDF"><i class="bi bi-file-pdf"></i></a>
</div>
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Abstract</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./intro.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Introduction</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./theoretical-framework.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Theoretical Framework</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./methodology.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Methodology</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./results.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Results</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./discussion.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Discussion</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./references.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">References</span></a>
  </div>
</li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#understanding-satellites-definition-and-common-features" id="toc-understanding-satellites-definition-and-common-features" class="nav-link active" data-scroll-target="#understanding-satellites-definition-and-common-features"><span class="header-section-number">2.1</span> Understanding satellites: definition and common features</a></li>
  <li><a href="#publicly-available-satellite-data-and-platforms-for-monitoring-coastal-shoreline-dynamics-a-comprehensive-overview" id="toc-publicly-available-satellite-data-and-platforms-for-monitoring-coastal-shoreline-dynamics-a-comprehensive-overview" class="nav-link" data-scroll-target="#publicly-available-satellite-data-and-platforms-for-monitoring-coastal-shoreline-dynamics-a-comprehensive-overview"><span class="header-section-number">2.2</span> Publicly available satellite data and platforms for monitoring coastal shoreline dynamics: a comprehensive overview</a>
  <ul class="collapse">
  <li><a href="#copernicus-browser" id="toc-copernicus-browser" class="nav-link" data-scroll-target="#copernicus-browser"><span class="header-section-number">2.2.1</span> Copernicus Browser</a></li>
  <li><a href="#planetscope-free-access-under-specific-conditions" id="toc-planetscope-free-access-under-specific-conditions" class="nav-link" data-scroll-target="#planetscope-free-access-under-specific-conditions"><span class="header-section-number">2.2.2</span> PlanetScope: free access under specific conditions</a></li>
  <li><a href="#rapideye-discontinued-in-2020" id="toc-rapideye-discontinued-in-2020" class="nav-link" data-scroll-target="#rapideye-discontinued-in-2020"><span class="header-section-number">2.2.3</span> RapidEye (discontinued in 2020)</a></li>
  </ul></li>
  <li><a href="#free-and-open-source-software-tools-that-could-be-used-for-monitoring-coastal-shoreline-fluctuations" id="toc-free-and-open-source-software-tools-that-could-be-used-for-monitoring-coastal-shoreline-fluctuations" class="nav-link" data-scroll-target="#free-and-open-source-software-tools-that-could-be-used-for-monitoring-coastal-shoreline-fluctuations"><span class="header-section-number">2.3</span> Free and open-Source software Tools that could be used for monitoring coastal shoreline fluctuations</a>
  <ul class="collapse">
  <li><a href="#qgis-strengths-and-limitations-in-geospatial-analysis" id="toc-qgis-strengths-and-limitations-in-geospatial-analysis" class="nav-link" data-scroll-target="#qgis-strengths-and-limitations-in-geospatial-analysis"><span class="header-section-number">2.3.1</span> QGIS: strengths and limitations in geospatial analysis</a></li>
  <li><a href="#geospatial-analysis-using-python-libraries" id="toc-geospatial-analysis-using-python-libraries" class="nav-link" data-scroll-target="#geospatial-analysis-using-python-libraries"><span class="header-section-number">2.3.2</span> Geospatial analysis using python libraries</a></li>
  <li><a href="#r-for-remote-sensing-capabilities-and-limitations" id="toc-r-for-remote-sensing-capabilities-and-limitations" class="nav-link" data-scroll-target="#r-for-remote-sensing-capabilities-and-limitations"><span class="header-section-number">2.3.3</span> R for remote sensing: capabilities and limitations</a></li>
  </ul></li>
  <li><a href="#panchromatic-and-pansharpened-satellite-imagery" id="toc-panchromatic-and-pansharpened-satellite-imagery" class="nav-link" data-scroll-target="#panchromatic-and-pansharpened-satellite-imagery"><span class="header-section-number">2.4</span> Panchromatic and pansharpened satellite imagery</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Theoretical Framework</span></h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  


</header>


<section id="understanding-satellites-definition-and-common-features" class="level2" data-number="2.1">
<h2 data-number="2.1" class="anchored" data-anchor-id="understanding-satellites-definition-and-common-features"><span class="header-section-number">2.1</span> Understanding satellites: definition and common features</h2>
<p>A satellite is an object that orbits around a larger celestial body due to gravitational forces. Natural satellites, such as the Earth orbiting the Sun or the Moon orbiting the Earth, are formed through natural processes and are an integral part of the universe’s structure. These celestial objects differ from artificial satellites, which are human-engineered and serve human-centric purposes.</p>
<p>The term <em>satellite</em> is most commonly associated with artificial satellites mechanisms designed and constructed by humans to perform a variety of tasks. These artificial satellites are launched into orbit around Earth or other celestial bodies to support diverse applications, including communication, Earth observation, navigation, and scientific exploration (Adams, 2017). Their versatility and functional diversity make them invaluable tools for advancing scientific knowledge, technological progress, and global connectivity.</p>
<p>Despite their varied applications, all satellites share fundamental operational features. A primary requirement is a reliable power source, typically solar panels, combined with a storage battery to ensure uninterrupted operation during periods without sunlight. As solar irradiance decreases proportionally to the square of the distance from the Sun (or any spherical source), it quickly becomes insufficient for powering satellites far beyond Earth’s orbit. Consequently, satellites operating at greater distances from the Sun depend on radioisotope thermoelectric generators (RTGs), which provide both electricity and heat to maintain equipment at operational temperatures <span class="citation" data-cites="nasa_cassinis_nodate">(<a href="references.html#ref-nasa_cassinis_nodate" role="doc-biblioref">NASA n.d.</a>)</span>. These energy systems enable satellites to sustain their core functions, including data acquisition, communication, and maneuvering in orbit. This combination of power, communication, and navigation systems underpins the essential functionality of satellites, making them adaptable to a broad range of tasks in space.</p>
</section>
<section id="publicly-available-satellite-data-and-platforms-for-monitoring-coastal-shoreline-dynamics-a-comprehensive-overview" class="level2" data-number="2.2">
<h2 data-number="2.2" class="anchored" data-anchor-id="publicly-available-satellite-data-and-platforms-for-monitoring-coastal-shoreline-dynamics-a-comprehensive-overview"><span class="header-section-number">2.2</span> Publicly available satellite data and platforms for monitoring coastal shoreline dynamics: a comprehensive overview</h2>
<section id="copernicus-browser" class="level3" data-number="2.2.1">
<h3 data-number="2.2.1" class="anchored" data-anchor-id="copernicus-browser"><span class="header-section-number">2.2.1</span> Copernicus Browser</h3>
<p>The Copernicus Browser is a vital online platform providing free and open access to geospatial data and imagery from the European Union’s Copernicus Earth Observation Program, managed by the European Space Agency (ESA). It grants users access to an extensive range of datasets, particularly from the Sentinel satellite constellation, enabling the detailed exploration of Earth’s surface for scientific, environmental, and commercial applications.<br>
The data is available in standard geospatial formats, such as GeoTIFF for raster imagery, ensuring seamless compatibility with geospatial analysis tools like QGIS, R, and Python. Users can download imagery at various resolutions, including 10m, 20m, and 60m, catering to different project requirements and levels of detail <span class="citation" data-cites="sinergise_solutions_copernicus_nodate">(<a href="references.html#ref-sinergise_solutions_copernicus_nodate" role="doc-biblioref">Sinergise Solutions n.d.</a>)</span>.</p>
</section>
<section id="planetscope-free-access-under-specific-conditions" class="level3" data-number="2.2.2">
<h3 data-number="2.2.2" class="anchored" data-anchor-id="planetscope-free-access-under-specific-conditions"><span class="header-section-number">2.2.2</span> PlanetScope: free access under specific conditions</h3>
<p>PlanetScope is a satellite platform operated by the company Planet, featuring a constellation of approximately 130 satellites. This constellation is capable of imaging the entire land surface of Earth every day, covering an impressive 200 million km² per day. The satellite imagery has a resolution of 3 meters per pixel, making it well-suited for detailed environmental and spatial analyses.<br>
A PlanetScope Scene Product represents a single framed image captured as part of the satellite’s continuous line-scan of the Earth’s surface. These scenes are individual segments within a strip of imagery, overlapping with one another, and are not aligned to a specific tiling grid system. This format allows for flexible use, but requires additional processing for some applications.<br>
One of the most remarkable aspects of PlanetScope is its accessibility. The platform offers freely available data samples and provides free access for students, academic researchers, and humanitarian projects through the Planet Education and Research Program <span class="citation" data-cites="planet_planetscope_2024">(<a href="references.html#ref-planet_planetscope_2024" role="doc-biblioref">Planet 2024a</a>)</span>.<br>
While PlanetScope boasts an impressive daily collection capacity and frequent revisits, its affordability and accessibility are perhaps its most standout features, ensuring that high-quality satellite data is available for a wide range of users and applications.</p>
</section>
<section id="rapideye-discontinued-in-2020" class="level3" data-number="2.2.3">
<h3 data-number="2.2.3" class="anchored" data-anchor-id="rapideye-discontinued-in-2020"><span class="header-section-number">2.2.3</span> RapidEye (discontinued in 2020)</h3>
<p>RapidEye, a satellite constellation, was in operation from 2009 to 2020 and was developed by the company Planet, which also operates PlanetScope, as mentioned earlier. The constellation consisted of five high-resolution satellites, each capable of capturing imagery with a spatial resolution of approximately 5 meters per pixel <span class="citation" data-cites="planet_rapideye_2024">(<a href="references.html#ref-planet_rapideye_2024" role="doc-biblioref">Planet 2024b</a>)</span>.<br>
RapidEye’s sensors captured imagery across five spectral bands: Red, Green, Blue, Red Edge, and Near Infrared. This capability made RapidEye highly valuable for applications in agriculture, forestry, and environmental monitoring. Furthermore, more than 70% of the images were acquired with a view angle of less than 10°, with a maximum view angle limited to 20°, ensuring minimal distortion and consistent high-quality data <span class="citation" data-cites="esa_rapideye_nodate">(<a href="references.html#ref-esa_rapideye_nodate" role="doc-biblioref">ESA n.d.</a>)</span>.<br>
The extensive archive of RapidEye imagery is available for research and educational purposes upon request, free of charge <span class="citation" data-cites="planet_planet_nodate">(<a href="references.html#ref-planet_planet_nodate" role="doc-biblioref">Planet n.d.</a>)</span>. This historical archive remains a critical resource for studying and analyzing changes in the Earth’s surface over time.</p>
</section>
</section>
<section id="free-and-open-source-software-tools-that-could-be-used-for-monitoring-coastal-shoreline-fluctuations" class="level2" data-number="2.3">
<h2 data-number="2.3" class="anchored" data-anchor-id="free-and-open-source-software-tools-that-could-be-used-for-monitoring-coastal-shoreline-fluctuations"><span class="header-section-number">2.3</span> Free and open-Source software Tools that could be used for monitoring coastal shoreline fluctuations</h2>
<section id="qgis-strengths-and-limitations-in-geospatial-analysis" class="level3" data-number="2.3.1">
<h3 data-number="2.3.1" class="anchored" data-anchor-id="qgis-strengths-and-limitations-in-geospatial-analysis"><span class="header-section-number">2.3.1</span> QGIS: strengths and limitations in geospatial analysis</h3>
<p>QGIS (Quantum Geographic Information System) is open-source, cross-platform software for efficient geospatial data management, visualization, analysis, and mapping. It is valued for its accessibility, flexibility, and integration capabilities across various geospatial technologies. One of the primary advantages of QGIS is its cost-effectiveness. As free software, it eliminates the financial barrier associated with many proprietary GIS platforms. It supports a wide range of vector and raster file formats. This compatibility allows users to work with nearly any geospatial data type, including shapefiles and GeoTIFFs <span class="citation" data-cites="map-site_qgis_nodate">(<a href="references.html#ref-map-site_qgis_nodate" role="doc-biblioref">Map-site n.d.</a>)</span>.<br>
For temporal or dynamic data, QGIS provides tools like TimeManager, which enables users to visualize changes over time. This is particularly useful for monitoring environmental changes <span class="citation" data-cites="map-site_qgis_nodate">(<a href="references.html#ref-map-site_qgis_nodate" role="doc-biblioref">Map-site n.d.</a>)</span>.<br>
QGIS is also highly extensible, offering a vast library of plug-ins to enhance its functionality. These plug-ins allow users to perform specialized tasks, such as georeferencing raster data, creating temporal animations, and automating processes through batch operations. The active development community continuously contributes new plug-ins and updates, ensuring that QGIS remains a dynamic and evolving tool. Another strength of QGIS is its user-friendly interface, which lowers the learning curve for beginners. Tutorials and extensive online resources make it accessible even for users with little to no prior experience in GIS. The software also supports advanced functionality, such as 3D visualization, time-series analysis, and complex spatial queries, making it suitable for both basic and advanced geospatial tasks.<br>
While QGIS is highly versatile, it does have limitations. The software integrates well with external tools, however, machine/deep learning and some other advanced geospatial tasks require additional software. For instance, QGIS does not natively support models like Convolutional Neural Networks (CNNs) or the Segment Anything Model (SAM), which are often essential for tasks like automated object detection and image segmentation in remote sensing <span class="citation" data-cites="gillian_qgis_nodate">(<a href="references.html#ref-gillian_qgis_nodate" role="doc-biblioref">Gillian n.d.</a>)</span>.</p>
</section>
<section id="geospatial-analysis-using-python-libraries" class="level3" data-number="2.3.2">
<h3 data-number="2.3.2" class="anchored" data-anchor-id="geospatial-analysis-using-python-libraries"><span class="header-section-number">2.3.2</span> Geospatial analysis using python libraries</h3>
<p>Python provides a comprehensive ecosystem for geospatial analysis, supporting a wide range of workflows, from preprocessing and analyzing raster and vector data to implementing advanced machine learning techniques. Its libraries, such as rasterio, geopandas, and xarray, are designed to handle geospatial data efficiently. For raster data, rasterio allows users to read, write, and manipulate formats like GeoTIFF, while geopandas extends Pandas to support spatial operations for vector data, including spatial joins and reprojections. Additionally, xarray enables the analysis of multidimensional raster datasets, such as time-series or climate data.<br>
Python’s integration with deep learning frameworks, such as TensorFlow and PyTorch, makes it particularly suited for complex geospatial tasks. Convolutional Neural Networks (CNNs) are widely implemented for tasks like land cover classification, object detection, and semantic segmentation. Models such as UNet, optimized for image segmentation, are frequently applied to delineate detailed land use patterns or identify structures in satellite imagery. Python also supports tools like the Segment Anything Model (SAM), which generalizes segmentation tasks across diverse datasets using minimal user input. SAM’s transformer-based architecture allows it to identify features like buildings, vegetation, or land boundaries in high-resolution imagery efficiently. These frameworks leverage GPU acceleration, allowing for the processing of large datasets <span class="citation" data-cites="setu_segment_2024">(<a href="references.html#ref-setu_segment_2024" role="doc-biblioref">Setu et al. 2024</a>)</span>.<br>
Visualization is another area where Python offers strengths. Libraries such as folium and plotly enable the creation of interactive maps, while matplotlib and cartopy provide robust tools for static visualizations with geospatial overlays. Python’s ability to connect with cloud-based platforms, such as Google Earth Engine (GEE), further enhances its capacity to process and analyze large-scale geospatial datasets without the need for significant local infrastructure.<br>
However, Python’s complexity can be a drawback. Its workflows often require combining multiple libraries, which can increase development time and lead to steeper learning curves. Additionally, while Python supports high-performance tasks like deep learning, setting up the required environment, including GPU dependencies, can be resource-intensive and technically demanding. For visualization, while Python provides dynamic tools, creating highly customized or publication-quality outputs may require additional effort compared to other geospatial tools <span class="citation" data-cites="priyadharshini_r_2015">(<a href="references.html#ref-priyadharshini_r_2015" role="doc-biblioref">Priyadharshini 2015</a>)</span>.<br>
In summary, Python’s geospatial libraries are well-suited for handling raster and vector data, integrating machine learning and deep learning techniques, and supporting cloud-based workflows. While its flexibility and advanced tools provide significant capabilities, they also introduce complexity that may require technical expertise and time to manage effectively.</p>
</section>
<section id="r-for-remote-sensing-capabilities-and-limitations" class="level3" data-number="2.3.3">
<h3 data-number="2.3.3" class="anchored" data-anchor-id="r-for-remote-sensing-capabilities-and-limitations"><span class="header-section-number">2.3.3</span> R for remote sensing: capabilities and limitations</h3>
<p>R has become a widely used tool for remote sensing analysis due to its extensive library of packages, its flexibility, and its ability to handle large spatial datasets. Remote sensing involves deriving valuable insights from satellite imagery or other remote platforms, often requiring extensive preprocessing, analysis, and visualization. With specialized packages like terra, sf, and stars, R provides robust solutions for many aspects of remote sensing workflows, from raster data handling to vector geometry operations.<br>
The terra package is a key tool for raster data processing in R, succeeding the raster package with enhanced efficiency for large datasets. Raster data, commonly derived from satellite imagery like Sentinel-2 or Landsat, represents spatially continuous information. With terra, users can manage multi-band rasters, crop to areas of interest, normalize reflectance values, and perform raster algebra for tasks such as NDVI (Normalized Difference Vegetation Index) calculations <span class="citation" data-cites="ghosh_remote_2023">(<a href="references.html#ref-ghosh_remote_2023" role="doc-biblioref">Ghosh and Hijmans 2023</a>)</span>. Its built-in functions for processing large files without exhausting memory make it particularly suitable for handling data from modern satellite missions, where file sizes can be enormous. It is also Supporting formats like GeoTIFF and JP2 <span class="citation" data-cites="wasser_how_2017">(<a href="references.html#ref-wasser_how_2017" role="doc-biblioref">Wasser 2017</a>)</span>.<br>
The sf package complements terra by focusing on vector data, such as points, lines, and polygons, which represent boundaries, infrastructure, or sampling locations. It adheres to the Simple Features standard, enabling seamless work with vector geometries and integration with raster datasets. This allows for workflows like extracting raster values for polygons or performing spatial overlays. The package integrates well with R’s data manipulation and visualization tools, such as dplyr and ggplot2, making it easy to create maps and conduct spatial analysis.<br>
For multidimensional datasets, the stars package offers a specialized approach, particularly for spatiotemporal data. Designed to handle raster cubes with dimensions like time and spectral bands, it is ideal for monitoring changes over time, such as vegetation dynamics or coastal erosion. Stars also integrates with sf for overlaying vector geometries on raster datasets, making it a valuable addition to R’s remote sensing ecosystem, despite being less widely adopted than terra <span class="citation" data-cites="ghosh_remote_2023">(<a href="references.html#ref-ghosh_remote_2023" role="doc-biblioref">Ghosh and Hijmans 2023</a>)</span>.<br>
When it comes to machine learning, R provides interfaces to frameworks like Keras and TensorFlow, enabling users to build and train neural networks for tasks such as land cover classification or object detection. In addition to these deep learning capabilities, R supports supervised learning models like random forests and support vector machines, as well as unsupervised methods like k-means clustering or hierarchical clustering. These methods are well-suited for tasks such as identifying land use patterns or segmenting satellite imagery based on spectral properties. While R is capable of implementing deep learning models, its adoption for advanced architectures like Convolutional Neural Networks (CNNs) is less common, particularly compared to Python. Unfortunately, tools like SAM are not readily available in R, requiring researchers to rely on Python for these capabilities. Nevertheless, R remains effective for many machine learning tasks in remote sensing, especially when focusing on traditional models and workflows that prioritize statistical and geospatial analysis <span class="citation" data-cites="priyadharshini_r_2015">(<a href="references.html#ref-priyadharshini_r_2015" role="doc-biblioref">Priyadharshini 2015</a>)</span>.<br>
Visualization is another area where R shows both strength and limitations. R’s ggplot2 and tmap are exceptional for creating static and high-quality visualizations. However, when it comes to dynamic and interactive visualizations of large datasets, tools like Python’s folium outperform R. While R’s leaflet package does provide interactivity, it lacks some of the advanced features required for visualizing large geospatial datasets interactively <span class="citation" data-cites="chege_comparing_2024">(<a href="references.html#ref-chege_comparing_2024" role="doc-biblioref">Chege 2024</a>)</span>.<br>
In conclusion, R is a powerful tool for remote sensing analysis, offering exceptional capabilities for raster and vector data processing through terra and sf, and advanced spatiotemporal analysis through stars. Its strengths lie in statistical modeling, data visualization, supervised learning, unsupervised learning, and integrating geospatial analysis with dashboards, such as those built with R Shiny. However, tasks involving deep learning workflows or highly specialized models like UNet or SAM are often better handled in Python.<br>
</p>
</section>
</section>
<section id="panchromatic-and-pansharpened-satellite-imagery" class="level2" data-number="2.4">
<h2 data-number="2.4" class="anchored" data-anchor-id="panchromatic-and-pansharpened-satellite-imagery"><span class="header-section-number">2.4</span> Panchromatic and pansharpened satellite imagery</h2>
<p>Panchromatic and pansharpened satellite imagery are essential tools in remote sensing, offering enhanced capabilities for observing and analyzing Earth’s surface. Panchromatic imagery, often abbreviated as PAN imagery, is a single-channel grayscale image that integrates visible light wavelengths red, green, and blue into a single band. This approach sacrifices spectral detail for improved spatial resolution, making it ideal for capturing fine surface features. The information contained in each pixel of a panchromatic image directly reflects the total intensity of solar radiation reflected by objects within the pixel and detected by the satellite sensor. As a result, PAN imagery provides sharp and detailed images that are highly suitable for spatial analysis <span class="citation" data-cites="shanshan_panchromatic_2022">(<a href="references.html#ref-shanshan_panchromatic_2022" role="doc-biblioref">Shanshan 2022</a>)</span>.<br>
A panchromatic band by itself produces black and white images with high spatial resolution. For example, satellites like Landsat 7 and 8 offer panchromatic images with a resolution of 15 meters per pixel, which is significantly higher than the 30-meter resolution of their multispectral counterparts. This higher resolution allows panchromatic imagery to assist individual spectral bands by making them "sharper," enhancing the visual and analytical clarity of satellite data <span class="citation" data-cites="eos_data_analytic_panchromatic_2021">(<a href="references.html#ref-eos_data_analytic_panchromatic_2021" role="doc-biblioref">Analytic 2021</a>)</span>.<br>
One of the most significant applications of panchromatic imagery is its role in panchromatic sharpening, or pansharpening. This process fuses the high-resolution spatial data from panchromatic images with the spectral information from lower-resolution multispectral images. The resulting pansharpened image combines the best of both worlds: the spatial resolution of the panchromatic image and the spectral richness of the multispectral data. Pansharpening produces high-resolution color images that are more visually detailed and analytically useful for various applications. This fusion process has proven particularly beneficial for mapping land use, monitoring vegetation, and studying urban environments. By enhancing the spatial detail while preserving spectral attributes, pansharpening enables more accurate classification of surface features and clearer delineation of boundaries <span class="citation" data-cites="mcauliffe_panchromatic_2021">(<a href="references.html#ref-mcauliffe_panchromatic_2021" role="doc-biblioref">McAuliffe 2021</a>)</span>.<br>
The process of pansharpening relies on techniques that integrate the complementary strengths of panchromatic and multispectral imagery. Various methods are used, including HSV sharpening and Gram-Schmidt pansharpening. Each method offers specific advantages, depending on the application. For example, HSV sharpening works within the HSV color space, where <em>H</em> stands for hue, <em>S</em> for saturation, and <em>V</em> for value (brightness). In this method, the high-resolution panchromatic data replaces the lower-resolution <em>value</em> component of the multispectral image, while the hue and saturation components remain unchanged. This ensures the resulting image retains its original color characteristics but with improved sharpness and detail derived from the panchromatic band. This approach is straightforward and computationally efficient, making it widely used for applications requiring enhanced visuals <span class="citation" data-cites="arcgis_grundlagen_nodate">(<a href="references.html#ref-arcgis_grundlagen_nodate" role="doc-biblioref">ArcGIS n.d.</a>)</span>.<br>
On the other hand, Gram-Schmidt pansharpening is a more complex method that models the panchromatic band as a linear combination of the multispectral bands. This technique simulates a panchromatic band from the spectral information of the multispectral image, aligning it with the actual high-resolution panchromatic data. The simulated and actual data are then fused to create a highly accurate pansharpened image. Gram-Schmidt pansharpening is particularly effective in applications where preserving the spectral integrity of the multispectral data is critical, such as in scientific studies of vegetation health or water quality <span class="citation" data-cites="arcgis_grundlagen_nodate">(<a href="references.html#ref-arcgis_grundlagen_nodate" role="doc-biblioref">ArcGIS n.d.</a>)</span>.</p>


<div id="refs" class="references csl-bib-body hanging-indent" data-entry-spacing="0" role="list" style="display: none">
<div id="ref-eos_data_analytic_panchromatic_2021" class="csl-entry" role="listitem">
Analytic, EOS Data. 2021. <span>“Panchromatic <span>Imagery</span> <span>And</span> <span>Its</span> <span>Band</span> <span>Combinations</span> <span>In</span> <span>Use</span>.”</span> <a href="https://eos.com/make-an-analysis/panchromatic/">https://eos.com/make-an-analysis/panchromatic/</a>.
</div>
<div id="ref-arcgis_grundlagen_nodate" class="csl-entry" role="listitem">
ArcGIS. n.d. <span>“Grundlagen Zu <span>Pan</span>-<span>Sharpening</span>—<span>Hilfe</span> <span></span> <span>ArcGIS</span> for <span>Desktop</span>.”</span> Accessed December 11, 2024. <a href="https://desktop.arcgis.com/de/arcmap/10.3/manage-data/raster-and-images/fundamentals-of-panchromatic-sharpening.htm">https://desktop.arcgis.com/de/arcmap/10.3/manage-data/raster-and-images/fundamentals-of-panchromatic-sharpening.htm</a>.
</div>
<div id="ref-chege_comparing_2024" class="csl-entry" role="listitem">
Chege, Stephen. 2024. <span>“Comparing <span>R</span> <span>VS</span> <span>Python</span> for <span>Geospatial</span> <span>Science</span>.”</span> <em>The Deep Hub</em>. <a href="https://medium.com/thedeephub/comparing-r-vs-python-for-geospatial-science-881787683c41">https://medium.com/thedeephub/comparing-r-vs-python-for-geospatial-science-881787683c41</a>.
</div>
<div id="ref-esa_rapideye_nodate" class="csl-entry" role="listitem">
ESA. n.d. <span>“<span>RapidEye</span> - <span>Earth</span> <span>Online</span>.”</span> Accessed December 2, 2024. <a href="https://earth.esa.int/eogateway/missions/rapideye#instruments-section">https://earth.esa.int/eogateway/missions/rapideye#instruments-section</a>.
</div>
<div id="ref-ghosh_remote_2023" class="csl-entry" role="listitem">
Ghosh, Aniruddha, and Robert J Hijmans. 2023. <span>“Remote <span>Sensing</span> <span>Image</span> <span>Analysis</span> with <span>R</span>.”</span>
</div>
<div id="ref-gillian_qgis_nodate" class="csl-entry" role="listitem">
Gillian, Palino. n.d. <span>“<span>QGIS</span>: <span>An</span> <span>Introduction</span> to an <span>Open</span>-<span>Source</span> <span>Geographic</span> <span>Information</span> <span>System</span> <span></span> <span>Mississippi</span> <span>State</span> <span>University</span> <span>Extension</span> <span>Service</span>.”</span> Accessed December 5, 2024. <a href="http://extension.msstate.edu/publications/qgis-introduction-open-source-geographic-information-system">http://extension.msstate.edu/publications/qgis-introduction-open-source-geographic-information-system</a>.
</div>
<div id="ref-map-site_qgis_nodate" class="csl-entry" role="listitem">
Map-site. n.d. <span>“<span>QGIS</span> <span>Advanced</span> [<span>Lernplattform</span> Für <span>OpenSource</span> <span>GIS</span>].”</span> Accessed December 5, 2024. <a href="https://lernplattform.map-site.de/doku.php/qgis/advanced/start">https://lernplattform.map-site.de/doku.php/qgis/advanced/start</a>.
</div>
<div id="ref-mcauliffe_panchromatic_2021" class="csl-entry" role="listitem">
McAuliffe, Kellen. 2021. <span>“Panchromatic <span>Imaging</span>.”</span> <em>ArcGIS StoryMaps</em>. <a href="https://storymaps.arcgis.com/stories/28a2091d2819476c8c8fac573798e912">https://storymaps.arcgis.com/stories/28a2091d2819476c8c8fac573798e912</a>.
</div>
<div id="ref-nasa_cassinis_nodate" class="csl-entry" role="listitem">
NASA. n.d. <span>“Cassini’s <span>Radioisotope</span> <span>Thermoelectric</span> <span>Generators</span> (<span>RTGs</span>) - <span>NASA</span> <span>Science</span>.”</span> Accessed December 11, 2024. <a href="https://science.nasa.gov/mission/cassini/radioisotope-thermoelectric-generator/">https://science.nasa.gov/mission/cassini/radioisotope-thermoelectric-generator/</a>.
</div>
<div id="ref-planet_planetscope_2024" class="csl-entry" role="listitem">
Planet. 2024a. <span>“<span>PlanetScope</span> Übersicht.”</span> <a href="https://developers.planet.com/docs/data/planetscope/">https://developers.planet.com/docs/data/planetscope/</a>.
</div>
<div id="ref-planet_rapideye_2024" class="csl-entry" role="listitem">
———. 2024b. <span>“<span>RapidEye</span> <span>Overview</span>.”</span> <a href="https://developers.planet.com/docs/data/rapideye/">https://developers.planet.com/docs/data/rapideye/</a>.
</div>
<div id="ref-planet_planet_nodate" class="csl-entry" role="listitem">
———. n.d. <span>“Planet <span>Science</span> <span>Programs</span>: <span>Satellite</span> <span>Imagery</span> <span>Access</span> for <span>Researchers</span> <span></span> <span>Planet</span>.”</span> Accessed December 10, 2024. <a href="https://www.planet.com/science/">https://www.planet.com/science/</a>.
</div>
<div id="ref-priyadharshini_r_2015" class="csl-entry" role="listitem">
Priyadharshini. 2015. <span>“R Vs <span>Python</span> - <span>What</span> Should <span>I</span> Learn?”</span> <em>Battle of the Programming Languages: R Vs Python</em>. <a href="https://www.simplilearn.com/r-vs-python-battle-of-programming-languages-article">https://www.simplilearn.com/r-vs-python-battle-of-programming-languages-article</a>.
</div>
<div id="ref-setu_segment_2024" class="csl-entry" role="listitem">
Setu, Jahanggir, Mahmudul Islam, Syed Pasha, Nabarun Halder, Ekram Hossain, Asif Mahmud, Ashraful Islam, Md Alam, and M. Amin. 2024. <em>Segment <span>Anything</span> <span>Model</span> (<span>SAM</span> 2) <span>Unveiled</span>: <span>Functionality</span>, <span>Applications</span>, and <span>Practical</span> <span>Implementation</span> <span>Across</span> <span>Multiple</span> <span>Domains</span></em>. <a href="https://doi.org/10.20944/preprints202408.1790.v1">https://doi.org/10.20944/preprints202408.1790.v1</a>.
</div>
<div id="ref-shanshan_panchromatic_2022" class="csl-entry" role="listitem">
Shanshan. 2022. <span>“Panchromatic <span>Image</span> - an Overview <span></span> <span>ScienceDirect</span> <span>Topics</span>.”</span> <a href="https://www.sciencedirect.com/topics/computer-science/panchromatic-image">https://www.sciencedirect.com/topics/computer-science/panchromatic-image</a>.
</div>
<div id="ref-sinergise_solutions_copernicus_nodate" class="csl-entry" role="listitem">
Sinergise Solutions. n.d. <span>“Copernicus <span>Data</span> <span>Space</span> <span>Ecosystem</span>.”</span> Accessed December 10, 2024. <a href="https://www.sentinel-hub.com/explore/copernicus-data-space-ecosystem/">https://www.sentinel-hub.com/explore/copernicus-data-space-ecosystem/</a>.
</div>
<div id="ref-wasser_how_2017" class="csl-entry" role="listitem">
Wasser, Leah. 2017. <span>“How to <span>Open</span> and <span>Use</span> <span>Files</span> in <span>Geotiff</span> <span>Format</span>.”</span> <em>Earth Data Science - Earth Lab</em>. <a href="https://www.earthdatascience.org/courses/earth-analytics/lidar-raster-data-r/introduction-to-spatial-metadata-r/">https://www.earthdatascience.org/courses/earth-analytics/lidar-raster-data-r/introduction-to-spatial-metadata-r/</a>.
</div>
</div>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp('/' + window.location.host + '/');
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="./intro.html" class="pagination-link" aria-label="Introduction">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Introduction</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="./methodology.html" class="pagination-link" aria-label="Methodology">
        <span class="nav-page-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Methodology</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->




</body></html>